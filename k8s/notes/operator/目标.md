





# 原计划

1. 构建一个controller业务-调谐之后更新status
   + get之后可以看到状态
   + 调谐过程打印日志
   + makefile dockerfile rbac
2. operator工作流
   + 如何注册过滤函数
   + 如何增加并发数量
3. 源码
   + client-go
   + controller-runtime













```go
package controllers

import (
	"context"

	"fmt"
	"github.com/go-logr/logr"
	corev1 "k8s.io/api/core/v1"
	"k8s.io/apimachinery/pkg/runtime"
	ctrl "sigs.k8s.io/controller-runtime"
	"sigs.k8s.io/controller-runtime/pkg/client"

	metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
	labels "k8s.io/apimachinery/pkg/labels"
	controllerutil "sigs.k8s.io/controller-runtime/pkg/controller/controllerutil"

	batchv1alpha1 "tutorial.kubebuilder.io/imoocpod/api/v1alpha1"
)

// ImoocPodReconciler reconciles a ImoocPod object
type ImoocPodReconciler struct {
	client.Client
	Log    logr.Logger
	Scheme *runtime.Scheme
}

func newPodForCR(cr *batchv1alpha1.ImoocPod) *corev1.Pod {
	labels := map[string]string{"app": cr.Name}
	return &corev1.Pod{
		ObjectMeta: metav1.ObjectMeta{
			GenerateName: cr.Name + "-pod",
			Namespace:    cr.Namespace,
			Labels:       labels,
		},
		Spec: corev1.PodSpec{
			Containers: []corev1.Container{
				{
					Name:    "busybox",
					Image:   "busybox",
					Command: []string{"sleep", "3600"},
				},
			},
		},
	}
}

// +kubebuilder:rbac:groups=batch.tutorial.kubebuilder.io,resources=imoocpods,verbs=get;list;watch;create;update;patch;delete
// +kubebuilder:rbac:groups=batch.tutorial.kubebuilder.io,resources=imoocpods/status,verbs=get;update;patch

func (r *ImoocPodReconciler) Reconcile(req ctrl.Request) (ctrl.Result, error) {
	ctx := context.Background()
	logger := r.Log.WithValues("imoocpod", req.NamespacedName)
	logger.Info("start reconcile")

	// fetch the ImoocPod instance
	instance := &batchv1alpha1.ImoocPod{}
	if err := r.Client.Get(ctx, req.NamespacedName, instance); err != nil {
		/*
		   if errors.IsNotFound(err) {
		           return ctrl.Result{}, nil
		   }
		*/
		return ctrl.Result{}, err
	}

	// 1. 获取 name 对应的所有的 pod 的列表
	lbls := labels.Set{"app": instance.Name}
	existingPods := &corev1.PodList{}
	if err := r.Client.List(ctx, existingPods, &client.ListOptions{
		Namespace: req.Namespace, LabelSelector: labels.SelectorFromSet(lbls)}); err != nil {
		logger.Error(err, "fetching existing pods failed")
		return ctrl.Result{}, err
	}

	// 2. 获取 pod 列表中的 pod name
	var existingPodNames []string
	for _, pod := range existingPods.Items {
		if pod.GetObjectMeta().GetDeletionTimestamp() != nil {
			continue
		}
		if pod.Status.Phase == corev1.PodRunning || pod.Status.Phase == corev1.PodPending {
			existingPodNames = append(existingPodNames, pod.GetObjectMeta().GetName())
		}
	}

	// 4. pod.Spec.Replicas > 运行中的 len(pod.replicas)，比期望值小，需要 scale up create
	if instance.Spec.Replicas > len(existingPodNames) {
		logger.Info(fmt.Sprintf("creating pod, current and expected num: %d %d", len(existingPodNames), instance.Spec.Replicas))
		pod := newPodForCR(instance)
		if err := controllerutil.SetControllerReference(instance, pod, r.Scheme); err != nil {
			logger.Error(err, "scale up failed: SetControllerReference")
			return ctrl.Result{}, err
		}
		if err := r.Client.Create(ctx, &pod); err != nil {
			logger.Error(err, "scale up failed")
			return ctrl.Result{}, err
		}
	}
	// 5. pod.Spec.Replicas < 运行中的 len(pod.replicas)，比期望值大，需要 scale down delete
	if instance.Spec.Replicas < len(existingPodNames) {
		logger.Info(fmt.Sprintf("deleting pod, current and expected num: %d %d", len(existingPodNames), instance.Spec.Replicas))
		pod := existingPods.Items[0]
		existingPods.Items = existingPods.Items[1:]
		if err := r.Client.Delete(ctx, &pod); err != nil {
			logger.Error(err, "scale down failed")
			return ctrl.Result{}, err
		}
	}

	return ctrl.Result{Requeue: true}, nil
}

func (r *ImoocPodReconciler) SetupWithManager(mgr ctrl.Manager) error {
	return ctrl.NewControllerManagedBy(mgr).
		For(&batchv1alpha1.ImoocPod{}).
		Complete(r)
}
```





# 现计划

1. reconcile如何引入finalizer？级联删除

2. 提高并发效率（106  多个queue）

3. 容器化（每个pod跑一个make run； leader选举）（赋予系统资源的访问权限  rbac） 权限是如何挂载的？（secret）

4. webhook的机制 怎么用

   







# 踩坑

## 1.工具

1. **<u>*为什么原来能跑通的代码，用vscode就报一大堆错*</u>**

   + 主要是import的错，然后我点了一些修复建议，报了更多错。。。

   + 而且提示要go mod tidy

   + make run报错

     ```shell
     [root@tos056 imoocpod]# make run
     /root/go/bin/controller-gen object:headerFile="hack/boilerplate.go.txt" paths="./..."
     /root/go/pkg/mod/k8s.io/client-go@v0.17.2/discovery/discovery_client.go:29:2: module github.com/googleapis/gnostic@latest found (v0.5.7), but does not contain package github.com/googleapis/gnostic/OpenAPIv2
     /root/go/pkg/mod/k8s.io/kube-openapi@v0.0.0-20211115234752-e816edb12b65/pkg/util/proto/document.go:24:2: case-insensitive import collision: "github.com/googleapis/gnostic/openapiv2" and "github.com/googleapis/gnostic/OpenAPIv2"
     
     ```

   + go mod tidy报错

     ```go
     tutorial.kubebuilder.io/imoocpod/controllers imports
     	sigs.k8s.io/controller-runtime/pkg/client imports
     	sigs.k8s.io/controller-runtime/pkg/client/apiutil imports
     	k8s.io/client-go/discovery imports
     	github.com/googleapis/gnostic/OpenAPIv2: module github.com/googleapis/gnostic@latest found (v0.5.7), but does not contain package github.com/googleapis/gnostic/OpenAPIv2
     
     ```

     但是我根本不知道哪里要引用OpenAPIv2

   + 在我刚刚点了import的一个快速修复之后。。。go.mod新增了几行，make run又报了别的错
   
     ```shell
     [root@tos056 imoocpod]# make run
     /root/go/bin/controller-gen object:headerFile="hack/boilerplate.go.txt" paths="./..."
     /root/go/pkg/mod/k8s.io/client-go@v0.23.0/plugin/pkg/client/auth/exec/metrics.go:21:2: package io/fs is not in GOROOT (/usr/local/go/src/io/fs)
     ```
   
     go.mod新增的几行又没了。。。
     
   + ==原因==：
   
     我用的是kubebuilder2.3.1，生成的go.mod中require的包版本也较低，然后不知道为啥，用vscode打开之后报很多import错，然后我点击了vscode的傻瓜式的快速修复，它把我的require都换成了最新版本的包，接口都变了，所以我原来按老版本生成的代码就跑不通了。
   
   + ==解决方法：==
   
     用kubebuilder2.3.1重新生成一个项目，这样就可以获得require的包的版本到底是什么了。
   
   + ==经验教训：==
   
     + 不要点击vscode的快速修复，它的快速修复通常比较傻
     + 把自己的项目用git管理
   
   

## 2.部署

1. **<u>*make docker-build时，到go mod download报错*</u>**`go: github.com/go-logr/logr@v0.1.0: Get https://goproxy.cn/github.com/go-logr/logr/@v/v0.1.0.mod: dial tcp: lookup goproxy.cn on 172.18.120.1:53: dial udp 172.18.120.1:53: connect: network is unreachable`

   **原因**：

   容器里网络有可能有问题

   **解决方案**：

   用本地网络即`docker build --network=host`

2. 系列问题：

   1. **<u>*每次重新启动controller那个pod，原来创建的CR都没了。*</u>**
   2. **<u>*每次更换controller的镜像并重新启动时，原来创建的CR和CRD都没了*</u>**，
   3. 并且，有时，delete之后，crd还在，但是重新apply之后就不在了。。此时，log中有，DeletTimestamp != 0

   **<u>*问题2*</u>**：

   **原因**：

   kubeclt delete kustomize生成的那个yaml时删除了CRD

   **解决方案：**

   make install再生成一遍crd

   