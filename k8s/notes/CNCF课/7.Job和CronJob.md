操作演示即参考：

https://edu.aliyun.com/lesson_1651_13083#_13083



# 1.Job



## 1.1背景

1. 我们知道 K8s 里面，最小的调度单元是 Pod，我们可以直接通过 Pod 来运行任务进程。这样做将会产生以下几种问题：
2. 我们如何保证 Pod 内进程**正确的结束**？
3. 如何保证进程运行**失败后重试**？
4. 如何管理**多个任务**，且任务之间有**依赖关系**？
5. 如何**并行**地运行任务，并管理任务的**队列大小**？





## 1.2Job提供的功能

1. 首先 kubernetes 的 Job 是一个==管理任务的控制器==，它可以创建一个或多个 Pod 来指定 Pod 的数量，并可以**监控**它是否成功地运行或终止；
2. 我们可以根据 Pod 的状态来给 Job **设置**重置的**方式**及重试的**次数**；
3. 我们还可以根据**依赖关系**，保证上一个任务运行完成之后再运行下一个任务；
4. 同时还可以**控制任务的并行度**，根据并行度来确保 Pod 运行过程中的并行次数和总体完成大小。



## 1.3语法

![img](https://edu.aliyun.com/files/course/2021/04-02/1646306b25ea647399.jpeg)

1. 上图是 Job 最简单的一个 yaml 格式，这里主要新引入了一个 kind 叫 Job，这个 Job 其实就是 job-controller 里面的一种类型。 

   然后 metadata 里面的 name 来指定这个 Job 的名称，下面 `spec.template `里面其实就是 **pod** 的 **spec**。

2. 这里面的内容都是一样的，唯一多了两个点：

   + 第一个是 **restartPolicy**，在 Job 里面我们可以设置 `Never`、`OnFailure`、`Always `这三种重试策略。在希望 Job 需要重新运行的时候，我们可以用 Never；希望在失败的时候再运行，再重试可以用 OnFailure；或者不论什么情况下都重新运行时 Alway；
   + 另外，Job 在运行的时候不可能去无限的重试，所以我们需要一个参数来控制重试的次数。这个 **backoffLimit** 就是来保证一个 Job 到底能重试多少次。

   所以在 Job 里面，我们主要重点关注的一个是 **restartPolicy 重启策略**和 **backoffLimit 重试次数限制**。



## 1.4Job状态

![img](https://edu.aliyun.com/files/course/2021/04-02/1647131e60ce691348.png)

1. Job 创建完成之后，我们就可以通过 kubectl get jobs 这个命令，来查看当前 job 的运行状态。得到的值里面，基本就有 Job 的名称、当前完成了多少个 Pod，进行多长时间。
2. **AGE** 的含义是指这个 Pod 从当前时间算起，减去它当时创建的时间。这个时长主要用来告诉你 Pod 的历史、Pod 距今创建了多长时间。
3. **DURATION** 主要来看我们 Job 里面的<u>实际业务到底运行了多长时间</u>，当我们的性能调优的时候，这个参数会非常的有用。
4. **COMPLETIONS** 主要来看我们任务里面这个 Pod 一共有几个，然后它其中完成了多少个状态，会在这个字段里面做显示。



## 1.5查看pod

1. 下面我们来看一下 Pod，其实 ==Job 最后的执行单元还是 Pod==。

   我们刚才创建的 Job 会创建出来一个叫“pi”的一个 Pod，这个任务就是来计算这个圆周率，Pod 的名称会以“`${job-name}-${random-suffix}`”，我们可以看一下下面 Pod 的 yaml 格式。

   ![img](https://edu.aliyun.com/files/course/2021/04-02/164743f1655b681237.jpeg)

   

   

2. 它比普通的 Pod 多了一个叫 **ownerReferences**，这个东西来声明此 pod 是归哪个上一层 controller 来管理。可以看到这里的 ownerReferences 是归 batch/v1，也就是上一个 Job 来管理的。这里就声明了它的 controller 是谁，然后可以通过 pod 返查到它的控制器是谁，同时也能根据 Job 来查一下它下属有哪些 Pod。



## 1.6并行运行pod

1. 我们有时候有些需求：希望 Job 运行的时候可以**最大化的并行**，并行出 n 个 Pod 去快速地执行。

   同时，由于我们的节点数有限制，可能也不希望同时并行的 Pod 数过多，有那么一个管道的概念，我们可以希望最大的并行度是多少，Job 控制器都可以帮我们来做到。

2. 这里主要看两个参数：**一个是 completions，一个是 parallelism。**

   + 首先第一个参数是用来指定本 Pod 队列**执行次数**。可能这个不是很好理解，其实可以把它认为是这个 **Job** 指定的**可以运行的总次数**。比如这里设置成 8，即**这个任务一共会被执行 8 次**；
   + 第二个参数代表这个**并行执行的个数**。所谓并行执行的次数，其实就是一个管道或者缓冲器中缓冲队列的大小，把它设置成 2，也就是说这个 Job 一定要执行 8 次，每次并行 2 个 Pod，这样的话，一共会执行 4 个批次。

3. ![img](https://edu.aliyun.com/files/course/2021/04-02/164811bed3cd564718.png)

4. 下面来看一下它的实际运行效果，上图就是当这个 Job 整体运行完毕之后可以看到的效果，首先看到 job 的名字，然后看到它一共创建出来了 8 个 pod，执行了 2 分 23 秒。

5. 接着来看真正的 pods，pods 总共出来了 8 个 pod，每个 pod 的状态都是完成的，然后来看一下它的 AGE，就是时间。

   从下往上看，可以看到分别有 73s、40s、110s 和 2m26s。**每一组都有两个 pod 时间是相同的**，即：时间段是 40s 的时候是最后一个创建、 2m26s 是第一个创建的。

   也就是说，**总是两个 pod 同时创建出来**，并行完毕、消失，然后再创建、再运行、再完毕。

6. 比如说，刚刚我们其实通过**第二个参数**来控制了当前 Job 并行执行的次数，这里就可以了解到这个缓冲器或者说管道队列大小的作用。



# 2.CronJob

![img](https://edu.aliyun.com/files/course/2021/04-02/164850284db3319326.png)

1. 下面来介绍另外一个 Job，叫做 **CronJob**，其实也可以叫**定时运行 Job**。CronJob 其实和 Job 大体是相似的，**唯一的不同点**就是它**可以设计一个时间**。比如说可以定时在几点几分执行，特别适合晚上做一些清理任务，还有可以几分钟执行一次，几小时执行一次等等，这就叫==定时任务==。
2. 定时任务和 Job 相比会多几个不同的字段：
   + **schedule**：schedule 这个字段主要是设置时间格式，它的时间格式和 Linux 的 crontime 是一样的，所以直接根据 Linux 的 crontime 书写格式来书写就可以了。举个例子： */1 指每分钟去执行一下 Job，这个 Job 需要做的事情就是打印出大约时间，然后打印出“Hello from the kubernetes cluster” 这一句话；
   + **startingDeadlineSeconds：**即：每次运行 Job 的时候，它最长可以等多长时间，有时这个 Job 可能运行很长时间也不会启动。所以这时，如果超过较长时间的话，CronJob 就会停止这个 Job；
   + **concurrencyPolicy**：就是说是否允许并行运行。所谓的并行运行就是，比如说我每分钟执行一次，但是这个 Job 可能运行的时间特别长，假如两分钟才能运行成功，也就是第二个 Job 要到时间需要去运行的时候，上一个 Job 还没完成。如果这个 policy 设置为 true 的话，那么不管你前面的 Job 是否运行完成，每分钟都会去执行；如果是 false，它就会等上一个 Job 运行完成之后才会运行下一个；
   + **JobsHistoryLimit：**这个就是每一次 CronJob 运行完之后，它都会遗留上一个 Job 的运行历史、查看时间。当然这个额不能是无限的，所以需要设置一下历史存留数，一般可以设置默认 10 个或 100 个都可以，这主要取决于每个人集群不同，然后根据每个人的集群数来确定这个时间。





# 3.架构设计



## 3.1管理模式

![img](https://edu.aliyun.com/files/course/2021/04-02/1655153aab2b853829.png)



## 3.2Job-Controller

![img](https://edu.aliyun.com/files/course/2021/04-02/165542e6c9df606039.jpeg)

1. 上图是一个 Job 控制器的主要流程。

   所有的 job 都是一个 controller，它会 watch 这个 API Server，我们每次提交一个 Job 的 yaml 都会经过 api-server 传到 ETCD 里面去，然后 Job Controller 会注册几个 Handler，每当有添加、更新、删除等操作的时候，它会通过一个内存级的消息队列，发到 controller 里面。

2. 通过 Job Controller 检查当前是否有运行的 pod，如果没有的话，通过 Scale up 把这个 pod 创建出来；如果有的话，或者如果大于这个数，对它进行 Scale down，如果这时 pod 发生了变化，需要及时 Update 它的状态。

3. 同时要去**检查它是否是并行的 job**，或者是串行的 job，根据设置的配置并行度、串行度，及时地把 pod 的数量给创建出来。最后，它会把 job 的整个的状态更新到 API Server 里面去，这样我们就能看到呈现出来的最终效果了。